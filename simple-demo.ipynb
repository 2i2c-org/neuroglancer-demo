{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Neuroglancer JupyterLab Binder demo\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A brief demonstration of the [neuroglancer package repurposed for JupyterLab](https://github.com/2i2c-org/jupyter-neuroglancer). You can run these cells from top-to-bottom to see how Neuroglancer can be used in this interface.\n",
    "\n",
    ":::{note}\n",
    "This notebook was adapted from the [neuroglancer jupyter example notebook](https://github.com/google/neuroglancer/blob/master/python/examples/jupyter-notebook-demo.ipynb), with a two line addition to enable [jupyter-neuroglancer](https://github.com/2i2c-org/jupyter-neuroglancer) and some formatting changes for readability with [MyST-JupyterLab engine](https://mystmd.org).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroglancer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new viewer\n",
    "\n",
    "Create a new (initially empty) viewer.  This starts a webserver in a background thread, which serves a copy of the Neuroglancer client, and which also can serve local volume data and handles sending and receiving Neuroglancer state updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got my-action\n",
      "  Mouse position: [2977.1106 2984.811  3000.5002]\n",
      "  Layer selected values: Map({\"image\": {\"value\": 104}, \"overlay\": {}})\n",
      "Got my-action\n",
      "  Mouse position: [2977.1106 2984.811  3000.5002]\n",
      "  Layer selected values: Map({\"image\": {\"value\": 104}, \"overlay\": {}})\n"
     ]
    }
   ],
   "source": [
    "viewer = neuroglancer.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the viewer in JupyterLab\n",
    "Open the viewer as a pane in JupyterLab, using [jupyter-neuroglancer](https://github.com/yuvipanda/jupyter-neuroglancer). This handles securely authenticating when running remotely in a JupyterHub if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_neuroglancer import display_in_sidecar\n",
    "display_in_sidecar(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some image layers from cell data\n",
    "Add some example layers using the precomputed data source (HHMI Janelia FlyEM FIB-25 dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "  s.layers['image'] = neuroglancer.ImageLayer(source='precomputed://gs://neuroglancer-public-data/flyem_fib-25/image')\n",
    "  s.layers['segmentation'] = neuroglancer.SegmentationLayer(source='precomputed://gs://neuroglancer-public-data/flyem_fib-25/ground_truth', selected_alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight a subset of the data\n",
    "Display a numpy array as an additional layer.  A reference to the numpy array is kept only as long as the layer remains in the viewer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the viewer position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.voxel_coordinates = [3000.5, 3000.5, 3000.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hide the segmentation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layers['segmentation'].visible = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720026408.967548 21520099 gcs_resource.cc:109] Using default AdmissionQueue with limit 32\n",
      "W0000 00:00:1720026408.991029 21524268 curl_transport.cc:452] Error [6]=Couldn't resolve host name in curl operation\n",
      "Could not resolve host: metadata.google.internal\n",
      "E0000 00:00:1720026408.991158 21524273 google_auth_provider.cc:187] Could not find the credentials file in the standard gcloud location [/Users/choldgraf/.config/gcloud/application_default_credentials.json]. You may specify a credentials file using $GOOGLE_APPLICATION_CREDENTIALS, or to use Google application default credentials, run: gcloud auth application-default login\n"
     ]
    }
   ],
   "source": [
    "import tensorstore as ts\n",
    "\n",
    "image_vol = await ts.open({'driver': 'neuroglancer_precomputed', 'kvstore': 'gs://neuroglancer-public-data/flyem_fib-25/image/'})\n",
    "a = np.zeros((200,200,200), np.uint8)\n",
    "def make_thresholded(threshold):\n",
    "  a[...] = image_vol[3000:3200,3000:3200,3000:3200][...,0].read().result() > threshold\n",
    "make_thresholded(110)\n",
    "# This volume handle can be used to notify the viewer that the data has changed.\n",
    "volume = neuroglancer.LocalVolume(\n",
    "    a,\n",
    "    dimensions=neuroglancer.CoordinateSpace(\n",
    "        names=['x', 'y', 'z'],\n",
    "        units='nm',\n",
    "        scales=[8, 8, 8],\n",
    "    ),\n",
    "    voxel_offset=[3000, 3000, 3000])\n",
    "with viewer.txn() as s:\n",
    "  s.layers['overlay'] = neuroglancer.ImageLayer(\n",
    "        source=volume,\n",
    "      # Define a custom shader to display this mask array as red+alpha.\n",
    "        shader=\"\"\"\n",
    "void main() {\n",
    "  float v = toNormalized(getDataValue(0)) * 255.0;\n",
    "  emitRGBA(vec4(v, 0.0, 0.0, v));\n",
    "}\n",
    "\"\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the overlay volume, and call `invalidate()` to notify the Neuroglancer client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_thresholded(100)\n",
    "volume.invalidate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See the current state of the viewer\n",
    "\n",
    "Print the neuroglancer viewer state.  The Neuroglancer Python library provides a set of Python objects that wrap the JSON-encoded viewer state.  `viewer.state` returns a read-only snapshot of the state.  To modify the state, use the `viewer.txn()` function, or `viewer.set_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViewerState({\"dimensions\": {\"x\": [8e-09, \"m\"], \"y\": [8e-09, \"m\"], \"z\": [8e-09, \"m\"]}, \"position\": [3000.5, 3000.5, 3000.5], \"crossSectionScale\": 1, \"projectionScale\": 8192, \"layers\": [{\"type\": \"image\", \"source\": \"precomputed://gs://neuroglancer-public-data/flyem_fib-25/image\", \"tab\": \"source\", \"name\": \"image\"}, {\"type\": \"segmentation\", \"source\": \"precomputed://gs://neuroglancer-public-data/flyem_fib-25/ground_truth\", \"tab\": \"source\", \"selectedAlpha\": 0.3, \"segments\": [], \"name\": \"segmentation\", \"visible\": false}, {\"type\": \"image\", \"source\": \"python://volume/e98d9a6438faf27e8e5537469b8a57f92fde3363.231bf082be1b727fd32662478b2c661ebf2e15f1\", \"tab\": \"source\", \"shader\": \"\\nvoid main() {\\n  float v = toNormalized(getDataValue(0)) * 255.0;\\n  emitRGBA(vec4(v, 0.0, 0.0, v));\\n}\\n\", \"name\": \"overlay\"}], \"layout\": \"4panel\"})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the set of selected segments.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.state.layers['segmentation'].segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually update the state of the viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the state by calling `set_state` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c97d2ac4b58ee82735710da1ed575ccd12c07909'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "new_state = copy.deepcopy(viewer.state)\n",
    "new_state.layers['segmentation'].segments.add(10625)\n",
    "viewer.set_state(new_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a keyboard shortcut action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bind the 't' key in neuroglancer to a Python action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = 0\n",
    "def my_action(s):\n",
    "    global num_actions\n",
    "    num_actions += 1\n",
    "    with viewer.config_state.txn() as st:\n",
    "      st.status_messages['hello'] = ('Got action %d: mouse position = %r' %\n",
    "                                     (num_actions, s.mouse_voxel_coordinates))\n",
    "    print('Got my-action')\n",
    "    print(f'  Mouse position: {s.mouse_voxel_coordinates}')\n",
    "    print(f'  Layer selected values: {s.selected_values}')\n",
    "viewer.actions.add('my-action', my_action)\n",
    "with viewer.config_state.txn() as s:\n",
    "    s.input_event_bindings.viewer['keyt'] = 'my-action'\n",
    "    s.status_messages['hello'] = 'Welcome to this example'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the view layout to 3-d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layout = '3d'\n",
    "    s.projection_scale = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a screenshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a screenshot (useful for creating publication figures, or for generating videos).  While capturing the screenshot, we hide the UI and specify the viewer size so that we get a result independent of the browser size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Image\n",
    "\n",
    "screenshot = viewer.screenshot(size=[1000, 1000])\n",
    "screenshot_image = Image(value=screenshot.screenshot.image)\n",
    "screenshot_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the view layout to show the segmentation side by side with the image, rather than overlayed.  This can also be done from the UI by dragging and dropping.  The side by side views by default have synchronized position, orientation, and zoom level, but this can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layout = neuroglancer.row_layout(\n",
    "        [neuroglancer.LayerGroupViewer(layers=['image', 'overlay']),\n",
    "         neuroglancer.LayerGroupViewer(layers=['segmentation'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the overlay layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layout = neuroglancer.row_layout(\n",
    "        [neuroglancer.LayerGroupViewer(layers=['image']),\n",
    "         neuroglancer.LayerGroupViewer(layers=['segmentation'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a publicly-sharable URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a publicly sharable URL to the viewer state (only works for external data sources, not layers served from Python).  The Python objects for representing the viewer state (`neuroglancer.ViewerState` and friends) can also be used independently from the interactive Python-tied viewer to create Neuroglancer links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neuroglancer.to_url(viewer.state))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
